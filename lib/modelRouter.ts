// lib/modelRouter.ts
// æ™ºèƒ½æ¨¡å‹è·¯ç”± - æ ¹æ“šç”¨æˆ¶é¸æ“‡èª¿ç”¨å°æ‡‰ AI æ¨¡å‹

import { callGroqWithRetry, GROQ_MODELS } from './groqRouter';
import { callWithRetry as callHF } from './hfRouter';
import type { BertAnalysisResult } from './bertAnalyzer';

type ModelChoice = "llama" | "gpt" | "auto";

type Message = {
  role: "system" | "user" | "assistant";
  content: string;
};

export type ModelResponse = {
  content: string;
  model_used: string;
  provider: string;
  debug: any;
};

/**
 * æ§‹å»ºç³»çµ±æç¤ºè©ï¼ˆæ ¹æ“š BERT åˆ†æçµæœï¼‰
 */
function buildSystemPrompt(analysis: BertAnalysisResult): string {
  const { risk_score, sentiment_score, outline, keywords, urgency_level } = analysis;
  
  let prompt = [
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­ã€åŒç†å¿ƒå¼·çš„ä¸­æ–‡é†«ç™‚è«®è©¢åŠ©ç†ã€‚",
    "",
    "ã€é‡è¦è¦å‰‡ã€‘",
    "1. ä¸åšè¨ºæ–·ï¼Œåƒ…æä¾›ä¸€èˆ¬å¥åº·è³‡è¨Š",
    "2. ä½¿ç”¨æ¸…æ™°ã€æº«å’Œã€æ˜“æ‡‚çš„èªè¨€",
    "3. å…ˆç”¨ 1-2 å¥è©±è¡¨é”ç†è§£ï¼Œå†æä¾› 3-5 é»å…·é«”å»ºè­°",
    "4. å›ç­”è¦å¯¦ç”¨ã€å¯åŸ·è¡Œ",
    "",
    "ã€æ‚£è€…æƒ…æ³åˆ†æã€‘",
    `- é¢¨éšªè©•åˆ†ï¼š${(risk_score * 100).toFixed(0)}%`,
    `- æƒ…ç·’ç‹€æ…‹ï¼š${sentiment_score < 0.4 ? 'ç„¦æ…®/è² é¢' : sentiment_score > 0.6 ? 'æ­£é¢/ç©©å®š' : 'ä¸­æ€§'}`,
    `- ç·Šæ€¥ç¨‹åº¦ï¼š${urgency_level === 'high' ? 'âš ï¸ é«˜ï¼ˆå»ºè­°ç«‹å³å°±é†«ï¼‰' : urgency_level === 'medium' ? 'âš¡ ä¸­ç­‰ï¼ˆå»ºè­°ç›¡å¿«å°±é†«ï¼‰' : 'â„¹ï¸ ä½ï¼ˆå¯è§€å¯Ÿï¼‰'}`,
  ];
  
  if (keywords.length > 0) {
    prompt.push(`- é—œéµç—‡ç‹€ï¼š${keywords.join('ã€')}`);
  }
  
  if (outline.length > 0) {
    prompt.push(`- åˆ†æå¤§ç¶±ï¼š${outline.join('ï¼›')}`);
  }
  
  prompt.push("");
  
  // æ ¹æ“šé¢¨éšªç­‰ç´šèª¿æ•´å›æ‡‰ç­–ç•¥
  if (risk_score >= 0.7) {
    prompt.push("âš ï¸ ã€é«˜é¢¨éšªè­¦ç¤ºã€‘æ­¤æ‚£è€…å¯èƒ½éœ€è¦ç·Šæ€¥é†«ç™‚ç…§è­·ï¼Œè«‹åœ¨å›æ‡‰ä¸­æ˜ç¢ºå»ºè­°ç«‹å³å°±é†«æˆ–æ’¥æ‰“119ã€‚");
  } else if (risk_score >= 0.5) {
    prompt.push("âš¡ ã€ä¸­ç­‰é¢¨éšªã€‘å»ºè­°æ‚£è€…ç›¡å¿«å®‰æ’å°±é†«æª¢æŸ¥ï¼Œä¸è¦æ‹–å»¶ã€‚");
  }
  
  return prompt.join("\n");
}

/**
 * æ ¹æ“šæ¨¡å‹é¸æ“‡èª¿ç”¨å°æ‡‰çš„ AI
 */
export async function routeToModel(
  userMessage: string,
  analysis: BertAnalysisResult,
  modelChoice: ModelChoice,
  history: Message[] = []
): Promise<ModelResponse> {
  
  const systemPrompt = buildSystemPrompt(analysis);
  
  // æ§‹å»ºå®Œæ•´å°è©±
  const messages: Message[] = [
    { role: "system", content: systemPrompt },
    ...history.slice(-4), // åªä¿ç•™æœ€è¿‘2è¼ªå°è©±
    { role: "user", content: userMessage },
  ];
  
  try {
    if (modelChoice === "llama" || modelChoice === "auto") {
      // ä½¿ç”¨ Groq çš„ Llama 3 æ¨¡å‹
      const { content, debug } = await callGroqWithRetry(messages, {
        model: modelChoice === "llama" 
          ? GROQ_MODELS.LLAMA_3_8B 
          : GROQ_MODELS.LLAMA_3_8B, // auto ä¹Ÿç”¨ Llamaï¼ˆé€Ÿåº¦å¿«ï¼‰
        temperature: 0.7,
        max_tokens: 512,
      });
      
      return {
        content: content.trim(),
        model_used: debug.model || "llama-3-8b",
        provider: "groq",
        debug,
      };
    } 
    
    if (modelChoice === "gpt") {
      // ğŸ”¥ ä½¿ç”¨ Groq æä¾›çš„ GPT-OSS æ¨¡å‹
      const { content, debug } = await callGroqWithRetry(messages, {
        model: GROQ_MODELS.GPT_OSS_120B, // ä½¿ç”¨ 120B å¤§æ¨¡å‹
        temperature: 0.8,
        max_tokens: 768,
      });
      
      return {
        content: content.trim(),
        model_used: "gpt-oss-120b",
        provider: "groq",
        debug,
      };
    }
    
    throw new Error("æœªçŸ¥çš„æ¨¡å‹é¸æ“‡");
    
  } catch (error: any) {
    console.error("æ¨¡å‹èª¿ç”¨å¤±æ•—:", error);
    
    // å˜—è©¦ HF ä½œç‚ºå‚™ç”¨ï¼ˆå¦‚æœ Groq å¤±æ•—ï¼‰
    try {
      const { content, debug } = await callHF(
        "gpt2",
        "distilgpt2",
        messages,
        { temperature: 0.7, max_tokens: 512 }
      );
      
      return {
        content: content.trim(),
        model_used: "gpt2-fallback",
        provider: "huggingface",
        debug,
      };
    } catch {
      // æ‰€æœ‰å¤–éƒ¨ API éƒ½å¤±æ•—ï¼Œä½¿ç”¨æœ¬åœ°ç”Ÿæˆ
      return {
        content: generateLocalResponse(userMessage, analysis),
        model_used: "local-fallback",
        provider: "local",
        debug: { error: error.message },
      };
    }
  }
}

/**
 * æœ¬åœ°ç”Ÿæˆå›æ‡‰ï¼ˆç•¶æ‰€æœ‰ API éƒ½å¤±æ•—æ™‚ï¼‰
 */
function generateLocalResponse(message: string, analysis: BertAnalysisResult): string {
  const { risk_score, keywords, outline, urgency_level } = analysis;
  
  let response = ["æ„Ÿè¬æ‚¨çš„è«®è©¢ã€‚è®“æˆ‘ç‚ºæ‚¨åˆ†æï¼š", ""];
  
  // ç†è§£èˆ‡æ‘˜è¦
  if (keywords.length > 0) {
    response.push(`**æ‚¨æåˆ°çš„ä¸»è¦ç—‡ç‹€**ï¼š${keywords.slice(0, 3).join('ã€')}`);
    response.push("");
  }
  
  // é¢¨éšªè©•ä¼°
  if (urgency_level === "high") {
    response.push("âš ï¸ **é‡è¦æé†’**ï¼šæ ¹æ“šæ‚¨æè¿°çš„ç—‡ç‹€ï¼Œå»ºè­°æ‚¨ç«‹å³å°±é†«æˆ–æ’¥æ‰“119ã€‚é€™äº›ç—‡ç‹€å¯èƒ½éœ€è¦ç·Šæ€¥é†«ç™‚è™•ç½®ã€‚");
    response.push("");
  } else if (urgency_level === "medium") {
    response.push("âš¡ **å»ºè­°**ï¼šæ‚¨çš„ç—‡ç‹€éœ€è¦é†«ç™‚å°ˆæ¥­äººå“¡è©•ä¼°ï¼Œè«‹ç›¡å¿«å®‰æ’å°±é†«æª¢æŸ¥ã€‚");
    response.push("");
  }
  
  // ä¸€èˆ¬å»ºè­°
  response.push("**åŸºæœ¬å»ºè­°**ï¼š");
  response.push("");
  response.push("1. **è§€å¯Ÿè¨˜éŒ„**ï¼šç•™æ„ç—‡ç‹€çš„è®ŠåŒ–ã€é »ç‡å’Œåš´é‡ç¨‹åº¦");
  response.push("");
  response.push("2. **æ—¥å¸¸ä¿å¥**ï¼š");
  response.push("   - ä¿æŒå……è¶³ç¡çœ å’Œæ°´åˆ†");
  response.push("   - é¿å…éåº¦å‹ç´¯");
  response.push("   - æ³¨æ„é£²é£Ÿå‡è¡¡");
  response.push("");
  response.push("3. **å°±é†«æ™‚æ©Ÿ**ï¼š");
  response.push("   - ç—‡ç‹€æŒçºŒæˆ–åŠ é‡");
  response.push("   - å‡ºç¾æ–°çš„ç—‡ç‹€");
  response.push("   - å½±éŸ¿æ—¥å¸¸ç”Ÿæ´»");
  response.push("");
  
  if (risk_score >= 0.5) {
    response.push("âš ï¸ **é‡è¦**ï¼šä»¥ä¸Šå»ºè­°ä¸èƒ½æ›¿ä»£å°ˆæ¥­é†«ç™‚è¨ºæ–·ï¼Œè«‹å‹™å¿…å°±é†«æª¢æŸ¥ã€‚");
  } else {
    response.push("ğŸ’¡ **æé†’**ï¼šé€™äº›æ˜¯ä¸€èˆ¬æ€§å»ºè­°ï¼Œå¦‚æœ‰ç–‘æ…®è«‹è«®è©¢é†«ç™‚å°ˆæ¥­äººå“¡ã€‚");
  }
  
  return response.join("\n");
}